{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qX4y0PR_gFmA",
    "outputId": "fcf858ed-264e-43aa-e356-9cbaad4682ad"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time_series_module as tsm\n",
    "import time_series_cross_valid as tscv\n",
    "import time_series_versioning as tsver\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from importlib import reload\n",
    "from statsmodels.graphics import tsaplots\n",
    "from statsmodels.api import tsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GnNEgLaYgMqS"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_59790/2103511351.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date_time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m date_time_features = tsm.get_date_time_features(df, 'date_time', \n\u001b[0m\u001b[1;32m      4\u001b[0m                                                 \u001b[0mone_hot_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'hour'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'day'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'month'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'season'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                 hour = True, day = True, month = True, season = False, year = False)\n",
      "\u001b[0;32m~/notebooks/EPAM/practice_1/time_series_module.py\u001b[0m in \u001b[0;36mget_date_time_features\u001b[0;34m(data, dt_col, **params)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_date_time_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#one_hot_encoding : dict, hour = True, day = True, month = False, season = False, year = False):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mnew_date_time_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hour'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtemp_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'hour'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdt_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "date_time_features = tsm.get_date_time_features(df, 'date_time', \n",
    "                                                one_hot_encoding = {'hour' : True, 'day' : False, 'month' : False, 'season' : False}, \n",
    "                                                hour = True, day = True, month = True, season = False, year = False)\n",
    "\n",
    "#date_time_features = df[date_time_features_names].copy()\n",
    "date_time_column = df['date_time'].copy()\n",
    "df.drop(columns = ['date_time'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-25lhU9XgQ9h"
   },
   "outputs": [],
   "source": [
    "targets = ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = ['sensor_{}'.format(i) for i in range(1,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEqDIWEZ_uH8"
   },
   "outputs": [],
   "source": [
    "f_dict = {}\n",
    "df = tsm.feature_extractor(features_dict = f_dict, data_frame = df, inplace = True, \n",
    "                           STL = [date_time_column, targets + sensors,\n",
    "                                  True, False, 'additive'])\n",
    "df.drop(columns = sensors, inplace = True)\n",
    "#df = tsm.feature_extractor(features_dict = f_dict, data_frame = df, inplace = True, lagged = [list(df.columns), 24, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLQRO4J-NAE2"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n",
    "#date_time_features = date_time_features.loc[list(df.index),:]\n",
    "#date_time_column = date_time_column[df.index]\n",
    "#df.index, date_time_column.index, date_time_features.index = [list(range(len(df)))]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnoPXuTvgSBs"
   },
   "outputs": [],
   "source": [
    "def get_feature_list(data, date_time_features):\n",
    "    return [f for f in list(data.columns) if f not in targets and f not in date_time_features and f != 'date_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpKMK8kAhRSE"
   },
   "outputs": [],
   "source": [
    "features = get_feature_list(df, date_time_features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_versions = tsver.DataVersions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_versions.push(tsver.nested_data(df, features, targets, targets, [date_time_column, date_time_features]), \n",
    "                   key = 'original_data')\n",
    "data_versions.save_with_pickle('original_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-RHkYaRhUts"
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBi44i7fhVGs"
   },
   "outputs": [],
   "source": [
    "def mape(y, y_hat):\n",
    "    return 100*np.abs(y - y_hat) / y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-pTTHJzhobP"
   },
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1PLEW7VhZWD"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeModel:\n",
    "    def __init__(self, ridge):\n",
    "        self.ridge = ridge\n",
    "    def fit(self, X,Y):\n",
    "        fitted_model = self.ridge.fit(X, Y)\n",
    "        self.importances = fitted_model.coef_\n",
    "        return fitted_model\n",
    "    def predict(self, X):\n",
    "        return self.ridge.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIHut6pphbDc"
   },
   "outputs": [],
   "source": [
    "ridge_horizons = 1\n",
    "ridge_obj = Ridge(alpha = .001, normalize = True)\n",
    "ridge_model = RidgeModel(ridge_obj)\n",
    "ridge_CrossValid_params = {'train_size' : 2000, 'test_size' : 1, 'min_period' : 0, 'step' : 500}\n",
    "ridge_ForecastModel_params = {'features' : features, 'date_time' : date_time_features,\n",
    "                              'prior_lag' : 24, 'post_lag' : 0, 'new_index' : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UAnYXx7ihc8N"
   },
   "outputs": [],
   "source": [
    "ridge_quality = tscv.run_cv(data = df, targets = targets, horizons = ridge_horizons, CrossValid_params = ridge_CrossValid_params, \n",
    "            ForecastModel_params = ridge_ForecastModel_params, model = ridge_model, metrics = mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gwP2GmIGhfIA",
    "outputId": "4a887f26-89fa-4dc2-9d30-aa1a5fb8a724"
   },
   "outputs": [],
   "source": [
    "tscv.plot_cv_results(quality = ridge_quality, horizons = ridge_horizons, plot_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_losses = tscv.get_losses(ridge_quality, ridge_horizons)\n",
    "for tar in targets:\n",
    "    print(tar + ' train_loss: ',ridge_losses[tar]['train_loss'].mean())\n",
    "    print(tar + ' test_loss: ',ridge_losses[tar]['test_loss'].mean())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_resid = tscv.get_residuals(ridge_quality, ridge_horizons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_resid['target_benzene']['train_resid'].hist().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_losses['target_benzene']['train_loss'].hist().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_resid[targets[2]]['train_resid'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_columns = ridge_quality['target_benzene']['forecast_model'][0].features + ridge_quality['target_benzene']['forecast_model'][0].targets\n",
    "ridge_feature_corr = ridge_quality['target_benzene']['forecast_model'][0].data[ridge_columns].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge_feature_corr.loc[ridge_feature_corr.loc['lag_sensor_2_1'] >= 0.8, ridge_feature_corr.loc['lag_sensor_2_1'] >= 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_importances_dict = tscv.get_importances(ridge_quality, ridge_horizons)\n",
    "ridge_imp_features_0 = ridge_importances_dict['target_carbon_monoxide'][0]#[(ridge_importances_dict['target_carbon_monoxide'][0] >= .2) | (ridge_importances_dict['target_carbon_monoxide'][0] <= -0.2)]\n",
    "ridge_imp_features_1 = ridge_importances_dict['target_benzene'][0]\n",
    "ridge_imp_features_2 = list(ridge_importances_dict['target_nitrogen_oxides'][0][(ridge_importances_dict['target_nitrogen_oxides'][0] >= 1) | (ridge_importances_dict['target_nitrogen_oxides'][0] <= -1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_imp_features_1.apply(np.abs).sort_values(ascending = False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in ridge_imp_features_1.sort_values(ascending = False).apply(np.abs).index:\n",
    "    if 'sensor_2' in ind:\n",
    "        print(ind,ridge_imp_features_0.apply(np.abs)[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pd.concat([df[targets[0]].shift(1).dropna(), df[targets[1]]], axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_temp = ridge_quality['target_carbon_monoxide']['forecast_model'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = ridge_temp.data[ridge_temp.features + ridge_temp.date_time].copy()\n",
    "Y_temp = ridge_temp.data[ridge_temp.targets].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_cv = tscv.CrossValid(2000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import make_scorer\n",
    "MSE_scorer = make_scorer(MSE)\n",
    "sfs = SequentialFeatureSelector(ridge_obj, cv = list(sfs_cv.split(len(Y_temp), step = 500)), \n",
    "                                k_features = 20, scoring = MSE_scorer, forward = True)\n",
    "sfs = sfs.fit(X_temp, Y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_temp.data[list(sfs.k_feature_names_) + ridge_temp.targets].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#('lag_deg_C_1','lag_deg_C_2','lag_deg_C_3','lag_deg_C_4','lag_deg_C_5','lag_relative_humidity_1','lag_relative_humidity_2','lag_relative_humidity_3','lag_relative_humidity_4','lag_relative_humidity_5','lag_sensor_1_5','lag_sensor_2_5','lag_sensor_3_4','lag_sensor_4_4','lag_seasonal_target_carbon_monoxide_3','lag_resid_target_carbon_monoxide_1','lag_resid_target_carbon_monoxide_2','lag_resid_target_carbon_monoxide_3','lag_resid_target_benzene_2','lag_resid_target_benzene_3','lag_resid_target_nitrogen_oxides_1','lag_resid_target_nitrogen_oxides_2','lag_resid_target_nitrogen_oxides_3','lag_resid_target_nitrogen_oxides_5','h_0','h_6','h_8','h_9','h_10','h_12','h_13','h_14','h_15','h_16','h_17','h_18','h_20','h_21','h_23','day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxcUVO-JhtJZ"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('train.csv')\n",
    "df1['date_time'] = pd.to_datetime(df1['date_time'])\n",
    "date_time_features1 = tsm.get_date_time_features(df1, 'date_time', \n",
    "                                                one_hot_encoding = {'hour' : True, 'day' : True, 'month' : True, 'season' : True}, \n",
    "                                                hour = True, day = True, month = True, season = False, year = False)\n",
    "\n",
    "#date_time_features = df[date_time_features_names].copy()\n",
    "date_time_column1 = df1['date_time'].copy()\n",
    "df1.drop(columns = ['date_time'], inplace = True)\n",
    "f1_dict = {}\n",
    "df1 = tsm.feature_extractor(features_dict = f1_dict, data_frame = df1, inplace = True, \n",
    "                            STL = [date_time_column1, targets + sensors, True, False, 'additive'])\n",
    "df1.drop(columns = sensors, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = get_feature_list(df1)\n",
    "features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PQg8VUChwFE"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTRegModel:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    def fit(self, X, Y):\n",
    "        fitted_model = self.model.fit(X, Y)\n",
    "        self.importances = fitted_model.feature_importances_\n",
    "        return fitted_model\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOppg-e0hu6T"
   },
   "outputs": [],
   "source": [
    "dtreg_model = DTRegModel(DecisionTreeRegressor(max_depth = 11))\n",
    "dtreg_horizons = 1\n",
    "dtreg_CrossValid_params = {'train_size' : 2000, 'test_size' : 1, 'min_period' : 0, 'step' : 500}\n",
    "dtreg_ForecastModel_params = {'features' : features1, 'date_time' : date_time_features1,\n",
    "                              'prior_lag' : 24, 'post_lag' : 0, 'new_index' : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NXolG6PiUL8"
   },
   "outputs": [],
   "source": [
    "dtreg_quality = tscv.run_cv(data = df1, targets = targets, horizons = dtreg_horizons, CrossValid_params = dtreg_CrossValid_params, \n",
    "            ForecastModel_params = dtreg_ForecastModel_params, model = dtreg_model, metrics = mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_L6R2N9_iYAg",
    "outputId": "fbc3c900-5b20-4dba-8a00-af67196724d2"
   },
   "outputs": [],
   "source": [
    "tscv.plot_cv_results(quality = dtreg_quality, horizons = dtreg_horizons, plot_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtreg_importances_dict = tscv.get_importances(dtreg_quality, dtreg_horizons, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dtreg_imp_features_0 = list(dtreg_importances_dict['target_carbon_monoxide'][0][(dtreg_importances_dict['target_carbon_monoxide'][0] >= .001) | (dtreg_importances_dict['target_carbon_monoxide'][0] <= -0.001)].index)\n",
    "dtreg_imp_features_1 = list(dtreg_importances_dict['target_benzene'][0][(dtreg_importances_dict['target_benzene'][0] >= 1) | (dtreg_importances_dict['target_benzene'][0] <= -1)].index)\n",
    "dtreg_imp_features_2 = list(dtreg_importances_dict['target_nitrogen_oxides'][0][(dtreg_importances_dict['target_nitrogen_oxides'][0] >= 1) | (dtreg_importances_dict['target_nitrogen_oxides'][0] <= -1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtreg_losses = tscv.get_losses(dtreg_quality, dtreg_horizons)\n",
    "for tar in targets:\n",
    "    print(tar + ' train_loss: ',dtreg_losses[tar]['train_loss'].mean())\n",
    "    print(tar + ' test_loss: ',dtreg_losses[tar]['test_loss'].mean())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtlosses = {}\n",
    "for tar in targets:\n",
    "    dtlosses[tar] = {'train' : [], 'test' : []}\n",
    "tree_height_list = list(range(5,11))\n",
    "for tree_height in tree_height_list:\n",
    "    dtreg_model = DTRegModel(DecisionTreeRegressor(max_depth = tree_height))\n",
    "    dtreg_quality = tscv.run_cv(data = df, targets = targets, horizons = 2, CrossValid_params = dtreg_CrossValid_params, \n",
    "            ForecastModel_params = dtreg_ForecastModel_params, model = dtreg_model, metrics = mape)\n",
    "    dtreg_losses = tscv.get_losses(dtreg_quality, 2)\n",
    "    for tar in targets:\n",
    "        dtlosses[tar]['train'].append(dtreg_losses[tar]['train_loss'].mean())\n",
    "        dtlosses[tar]['test'].append(dtreg_losses[tar]['test_loss'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tar in targets:\n",
    "    plt.plot(tree_height_list, dtlosses[tar]['train'], label = 'train_' + tar)\n",
    "    plt.plot(tree_height_list, dtlosses[tar]['test'], label = 'test_' + tar)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtreg_importances_dict['target_benzene'][0].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NG5pfFliecA"
   },
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfdata = pd.read_csv('train.csv')\n",
    "rfdata['date_time'] = pd.to_datetime(rfdata['date_time'])\n",
    "rf_date_time_features = tsm.get_date_time_features(rfdata, 'date_time', \n",
    "                                                one_hot_encoding = {'hour' : True, 'day' : True, 'month' : True, 'season' : True}, \n",
    "                                                hour = True, day = True, month = True, season = False, year = False)\n",
    "\n",
    "rf_date_time_column = rfdata['date_time'].copy()\n",
    "rfdata.drop(columns = ['date_time'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_features_dict = {}\n",
    "rfdata = tsm.feature_extractor(features_dict = rf_features_dict, data_frame = rfdata, inplace = True, \n",
    "                            STL = [rf_date_time_column, targets + sensors, True, False, 'additive'])\n",
    "rfdata.drop(columns = sensors, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_features = get_feature_list(rfdata)\n",
    "rf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LH7zlHq0ifkB"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tp20RCZDijvC"
   },
   "outputs": [],
   "source": [
    "class RFReg_model:\n",
    "    def __init__(self, rfreg):\n",
    "        self.rfreg = rfreg\n",
    "    def fit(self, X, Y):\n",
    "        Y = np.reshape(Y, (Y.shape[0],))\n",
    "        fitted_model = self.rfreg.fit(X, Y)\n",
    "        self.importances = fitted_model.feature_importances_\n",
    "        return fitted_model\n",
    "    def predict(self, X):\n",
    "        return np.reshape(self.rfreg.predict(X), (X.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTSx3wd8iux0"
   },
   "outputs": [],
   "source": [
    "rfreg_model = RFReg_model(RandomForestRegressor(n_estimators = 35, max_depth = 5, bootstrap = False))\n",
    "rfreg_horizons = 1\n",
    "rfreg_CrossValid_params = {'train_size' : 2000, 'test_size' : 1, 'min_period' : 0, 'step' : 500}\n",
    "rfreg_ForecastModel_params = {'features' : rf_features + targets, 'date_time' : rf_date_time_features,\n",
    "                              'prior_lag' : 24, 'post_lag' : 0, 'new_index' : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHQhGDKvixA7"
   },
   "outputs": [],
   "source": [
    "rfreg_quality = tscv.run_cv(data = rfdata, targets = targets, horizons = rfreg_horizons, CrossValid_params = rfreg_CrossValid_params, \n",
    "            ForecastModel_params = rfreg_ForecastModel_params, model = rfreg_model, metrics = mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCGnBdjVtTDe"
   },
   "outputs": [],
   "source": [
    "tscv.plot_cv_results(quality = rfreg_quality, horizons = rfreg_horizons, plot_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg_losses = tscv.get_losses(rfreg_quality, rfreg_horizons)\n",
    "for tar in targets:\n",
    "    print(tar + ' train_loss: ',rfreg_losses[tar]['train_loss'].mean())\n",
    "    print(tar + ' test_loss: ',rfreg_losses[tar]['test_loss'].mean())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XrcBYTDrFPh"
   },
   "outputs": [],
   "source": [
    "#rfreg_quality['target_benzene']['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mnp7zyiRwyuK"
   },
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data = pd.read_csv('train.csv')\n",
    "xgb_data['date_time'] = pd.to_datetime(xgb_data['date_time'])\n",
    "xgb_date_time_features = tsm.get_date_time_features(xgb_data, 'date_time', \n",
    "                                                one_hot_encoding = {'hour' : False, 'day' : False, 'month' : False, 'season' : False},\n",
    "                                                hour = True, day = True, month = True, season = True, year = False)\n",
    "\n",
    "xgb_date_time_column = xgb_data['date_time'].copy()\n",
    "xgb_data.drop(columns = ['date_time'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_features_dict = {}\n",
    "#xgbdata = tsm.feature_extractor(features_dict = xgb_features_dict, data_frame = xgb_data, inplace = True, \n",
    "#                            STL = [xgb_date_time_column, targets, True, False, 'additive'])\n",
    "#xgbdata = tsm.feature_extractor(features_dict = xgb_features_dict, data_frame = xgb_data, inplace = True, \n",
    "#                            STL = [xgb_date_time_column, targets, True, False, 'additive'])\n",
    "#xgbdata.drop(columns = sensors, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data.drop(columns = ['sensor_3', 'sensor_4'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_features = get_feature_list(xgb_data, xgb_date_time_features)\n",
    "xgb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vP8eb6yLwyWw"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBRegModel:\n",
    "    def __init__(self, model, make_importances):\n",
    "        self.model = model\n",
    "        self.make_importances = make_importances\n",
    "    def fit(self, X, Y):\n",
    "        fitted_model = self.model.fit(X, Y)\n",
    "        self.importances = fitted_model.feature_importances_ if self.make_importances else None\n",
    "        return fitted_model\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QujVjAmYxqOW"
   },
   "outputs": [],
   "source": [
    "xgb_model = XGBRegModel(XGBRegressor(n_estimators = 10), make_importances = False)#, reg_alpha = 0.01, reg_lambda = 0.01))\n",
    "xgb_horizons = 1\n",
    "xgb_CrossValid_params = {'train_size' : 3500, 'test_size' : 1, 'min_period' : 0, 'step' : 500}\n",
    "xgb_ForecastModel_params = {'features' : xgb_features, 'date_time' : xgb_date_time_features,\n",
    "                              'prior_lag' : 24, 'post_lag' : 0, 'new_index' : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3zsPgqzLKXA",
    "outputId": "8873eb70-45c6-43ca-fbc6-bf1b5b442b4d"
   },
   "outputs": [],
   "source": [
    "xgb_quality = tscv.run_cv(data = xgb_data, targets = targets, horizons = xgb_horizons, CrossValid_params = xgb_CrossValid_params, \n",
    "                          ForecastModel_params = xgb_ForecastModel_params, model = xgb_model, metrics = mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_losses = tscv.get_losses(xgb_quality, xgb_horizons)\n",
    "for tar in targets:\n",
    "    print(tar + ' train_loss: ',xgb_losses[tar]['train_loss'].mean())\n",
    "    print(tar + ' test_loss: ',xgb_losses[tar]['test_loss'].mean())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 30, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BDhkZRW6LxE8",
    "outputId": "18b15f5c-0780-429a-8841-0aa9e33d36f0"
   },
   "outputs": [],
   "source": [
    "tscv.plot_cv_results(quality = xgb_quality, horizons = xgb_horizons, plot_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_losses, xgb_resids = tscv.get_losses(xgb_quality, xgb_horizons), tscv.get_residuals(xgb_quality, xgb_horizons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_quality[targets[0]]['forecast_model'][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_importances_dict = tscv.get_importances(xgb_quality, xgb_horizons, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_data = pd.read_csv('train.csv')\n",
    "lgb_data['date_time'] = pd.to_datetime(lgb_data['date_time'])\n",
    "lgb_dt_features = tsm.get_date_time_features(df, 'date_time', hour = [True, False], day = [True, False],\n",
    "                                                month = [True, False], season = [True, False], year = [False])\n",
    "\n",
    "lgb_date_time_column = lgb_data['date_time'].copy()\n",
    "lgb_data.drop(columns = ['date_time'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_features = get_feature_list(lgb_data, lgb_date_time_features)\n",
    "lgb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGBRegModel:\n",
    "    def __init__(self, model, make_importances):\n",
    "        self.model = model\n",
    "        self.make_importances = make_importances\n",
    "    def fit(self, X, Y):\n",
    "        fitted_model = self.model.fit(X, Y)\n",
    "        self.importances = fitted_model.feature_importances_ if self.make_importances else None\n",
    "        return fitted_model\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = LGBRegModel(LGBMRegressor(n_estimators = 350, max_depth = 1, boosting_type = 'dart'), make_importances = False)#, reg_alpha = 0.01, reg_lambda = 0.01))\n",
    "lgb_horizons = 1\n",
    "lgb_CrossValid_params = {'train_size' : 3500, 'test_size' : 1, 'min_period' : 0, 'step' : 500}\n",
    "lgb_ForecastModel_params = {'features' : lgb_features, 'date_time' : lgb_date_time_features,\n",
    "                              'prior_lag' : 24, 'post_lag' : 0, 'new_index' : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_quality = tscv.run_cv(data = lgb_data, targets = targets, horizons = lgb_horizons, CrossValid_params = lgb_CrossValid_params, \n",
    "                          ForecastModel_params = lgb_ForecastModel_params, model = lgb_model, metrics = mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_losses = tscv.get_losses(lgb_quality, lgb_horizons)\n",
    "for tar in targets:\n",
    "    print(tar + ' train_loss: ',lgb_losses[tar]['train_loss'].mean())\n",
    "    print(tar + ' test_loss: ',lgb_losses[tar]['test_loss'].mean())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "evaluation_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
